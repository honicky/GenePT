{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ec84f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html2text\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: html2text\n",
      "  Building wheel for html2text (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=af187fe8ca5aa9aba20968445ca5ffb234f15e7db400f944bfeb37a7fb5cbbaf\n",
      "  Stored in directory: /Users/rj/Library/Caches/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\n",
      "Successfully built html2text\n",
      "Installing collected packages: html2text\n",
      "Successfully installed html2text-2024.2.26\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e33a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import mygene\n",
    "import json\n",
    "import pickle\n",
    "mg = mygene.MyGeneInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636944e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_to_remove = [\n",
    "    \"##  Summary\\n\",\n",
    "    \"NEW\",\n",
    "    'Try the newGene table',\n",
    "    'Try the newTranscript table',\n",
    "    '**',\n",
    "    \"\\nGo to the top of the page Help\\n\"\n",
    "]\n",
    "\n",
    "def rough_text_from_gene_name(gene_number):\n",
    "    \n",
    "    # get url\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/gene/{gene_number}\"\n",
    "    # Send a GET request to the URL\n",
    "    summary_text = ''\n",
    "    soup = None\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('time out')\n",
    "        return((summary_text,soup))\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the \"summary\" tab content by inspecting the page's structure\n",
    "        summary_tab = soup.find('div', {'class': 'rprt-section gene-summary'})\n",
    "\n",
    "        # Check if the \"summary\" tab content is found\n",
    "        if summary_tab:\n",
    "            # Convert the HTML to plain text using html2text\n",
    "            html_to_text = html2text.HTML2Text()\n",
    "            html_to_text.ignore_links = True  # Ignore hyperlinks\n",
    "\n",
    "            # Extract the plain text from the \"summary\" tab\n",
    "            summary_text = html_to_text.handle(str(summary_tab))\n",
    "            # Remove the specified parts from the original text\n",
    "            for part in parts_to_remove:\n",
    "                summary_text = summary_text.replace(part, ' ')\n",
    "                # Replace '\\n' with a space\n",
    "            summary_text = summary_text.replace('\\n', ' ')\n",
    "\n",
    "            # Reduce multiple spaces into one space\n",
    "            summary_text = ' '.join(summary_text.split())\n",
    "            # Print or save the extracted text\n",
    "        else:\n",
    "            print(\"Summary tab not found on the page.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "    return((summary_text,soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gene CD24 as an example\n",
    "cd_24_name = mg.querymany('CD24', scopes='symbol', species='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name_to_tax_id = {}\n",
    "for result in cd_24_name:\n",
    "    if \"_id\" in result and \"query\" in result:\n",
    "        gene_name_to_tax_id[result['symbol']] = result['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80980bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name_to_tax_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d705d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name_to_summary_page = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e98122",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene_name, page_id in sorted(gene_name_to_tax_id.items()):\n",
    "    if gene_name not in gene_name_to_summary_page:\n",
    "        print('gene_name',gene_name)\n",
    "        parsed_text, unparsed_html = rough_text_from_gene_name(page_id)\n",
    "        gene_name_to_summary_page[gene_name] = parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name_to_summary_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9a9ac",
   "metadata": {},
   "source": [
    "### Experiment with Varied Gene Sets Tailored to Your Needs\n",
    "#### For any specific gene name, mygene can be utilized to translate it into page IDs. We've illustrated an example using gene vocabularies in scGPT and Geneformer. Download links for these files are available in the repository's README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d67f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.utils import download_gdrive_file\n",
    "\n",
    "scgpt_vocab_url = \"https://drive.google.com/file/d/1H3E_MJ-Dl36AQV6jLbna2EdvgPaqvqcC/view?usp=drive_link\"\n",
    "scgpt_vocab_path = \"data/vocab.json\"\n",
    "download_gdrive_file(scgpt_vocab_url, scgpt_vocab_path)\n",
    "vocab_gene = json.load(open(scgpt_vocab_path, 'rb'))\n",
    "vocab_gene_list = list(vocab_gene.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f5f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at data/token_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.utils import download_file\n",
    "import pickle\n",
    "\n",
    "geneformer_token_dict_url = \"https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/token_dictionary_gc95M.pkl\"\n",
    "geneformer_token_dict_path = \"data/token_dictionary.pkl\"\n",
    "download_file(geneformer_token_dict_url, geneformer_token_dict_path)\n",
    "token_dictionary = pickle.load(open(geneformer_token_dict_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d609d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6975 input query terms found dup hits:\t[('A2ML1-AS1', 2), ('A2ML1-AS2', 2), ('A2MP1', 2), ('AACSP1', 2), ('AADACL2-AS1', 3), ('AADACP1', 2)\n",
      "21975 input query terms found no hit:\t['5S_rRNA_ENSG00000276861', '5S_rRNA_ENSG00000277411', '5S_rRNA_ENSG00000277488', '5S_rRNA_ENSG00000\n",
      "7 input query terms found dup hits:\t[('ENSG00000267635', 2), ('ENSG00000268674', 3), ('ENSG00000275921', 2), ('ENSG00000278277', 3), ('E\n",
      "11 input query terms found no hit:\t['<cls>', '<eos>', '<mask>', '<pad>', 'ENSG00000139656', 'ENSG00000168078', 'ENSG00000189144', 'ENSG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example query to convert gene IDs into page ids for NCBI \n",
    "vocab_gene_list_results = mg.querymany(sorted(vocab_gene_list), scopes='symbol', species='human')\n",
    "token_dictionary_results = mg.querymany(sorted(token_dictionary.keys()), fields=\"symbol\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
